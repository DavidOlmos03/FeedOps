# FeedOps Configuration Guide

This guide explains how to configure data sources, customize workflows, and manage FeedOps settings.

## Table of Contents

- [Environment Variables](#environment-variables)
- [Data Source Configuration](#data-source-configuration)
- [Telegram Configuration](#telegram-configuration)
- [GitHub Configuration](#github-configuration)
- [Reddit Configuration](#reddit-configuration)
- [RSS Configuration](#rss-configuration)
- [Advanced Settings](#advanced-settings)
- [Workflow Customization](#workflow-customization)

## Environment Variables

All configuration is done through the `.env` file. Never commit this file to version control.

### Core Settings

```bash
# n8n Settings
N8N_HOST=0.0.0.0                    # Listen on all interfaces
N8N_PORT=5678                       # Web UI port
N8N_PROTOCOL=http                   # Use https in production
N8N_BASIC_AUTH_ACTIVE=true          # Enable authentication
N8N_BASIC_AUTH_USER=admin           # Username for n8n UI
N8N_BASIC_AUTH_PASSWORD=***         # Strong password recommended

# Webhook URL (use your domain in production)
WEBHOOK_URL=http://localhost:5678   # Used for webhook callbacks
```

### Database Settings

```bash
POSTGRES_HOST=postgres              # Service name from docker-compose
POSTGRES_PORT=5432
POSTGRES_DB=n8n
POSTGRES_USER=n8n
POSTGRES_PASSWORD=***               # Generated by generate-keys.sh
```

### Application Settings

```bash
TZ=UTC                              # Timezone for logs and schedules
LOG_LEVEL=info                      # debug, info, warn, error
NOTIFICATION_RETENTION_DAYS=30      # How long to keep history
MAX_RETRIES=3                       # Retry attempts for failed operations
RETRY_BACKOFF_MULTIPLIER=2          # Exponential backoff multiplier
```

## Data Source Configuration

Data sources are configured in the PostgreSQL database, not in environment variables. This allows dynamic management without restarts.

### Adding Data Sources

#### Via PostgreSQL CLI

```bash
# Access database
docker-compose exec postgres psql -U n8n -d n8n

# Add a source
INSERT INTO feed_sources (source_type, source_identifier, config, enabled)
VALUES ('rss', 'https://example.com/feed.xml', '{"keywords": "docker"}', true);
```

#### Via SQL File

Create `add-sources.sql`:
```sql
-- GitHub Repository
INSERT INTO feed_sources (source_type, source_identifier, config, enabled) VALUES
('github', 'owner/repository', '{"events": ["push", "release"]}', true);

-- Reddit Subreddit
INSERT INTO feed_sources (source_type, source_identifier, config, enabled) VALUES
('reddit', 'r/programming', '{"min_score": 50, "keywords": "golang,rust"}', true);

-- RSS Feed
INSERT INTO feed_sources (source_type, source_identifier, config, enabled) VALUES
('rss', 'https://hnrss.org/newest', '{"keywords": "kubernetes,docker"}', true);
```

Execute:
```bash
docker-compose exec -T postgres psql -U n8n -d n8n < add-sources.sql
```

### Viewing Data Sources

```bash
docker-compose exec postgres psql -U n8n -d n8n -c \
  "SELECT id, source_type, source_identifier, enabled, last_check FROM feed_sources;"
```

### Disabling a Source

```bash
docker-compose exec postgres psql -U n8n -d n8n -c \
  "UPDATE feed_sources SET enabled = false WHERE source_identifier = 'owner/repo';"
```

### Removing a Source

```bash
docker-compose exec postgres psql -U n8n -d n8n -c \
  "DELETE FROM feed_sources WHERE source_identifier = 'owner/repo';"
```

## Telegram Configuration

### 1. Create a Telegram Bot

1. Open Telegram and search for `@BotFather`
2. Send `/newbot` command
3. Follow prompts to name your bot
4. Copy the bot token (looks like `123456789:ABCdefGHIjklMNO...`)

### 2. Get Your Chat ID

#### For Direct Messages:

1. Send any message to your bot
2. Visit: `https://api.telegram.org/bot<YOUR_BOT_TOKEN>/getUpdates`
3. Find `"chat":{"id":123456789}` in the response
4. That number is your chat ID

#### For Groups/Channels:

1. Add your bot to the group/channel
2. Send a message in the group: `/start@YourBotName`
3. Visit the getUpdates URL above
4. Find the group chat ID (negative number: `-1001234567890`)

### 3. Configure in .env

```bash
TELEGRAM_BOT_TOKEN=123456789:ABCdefGHIjklMNOpqrsTUVwxyz
TELEGRAM_DEFAULT_CHAT_ID=-1001234567890

# Optional: Separate channel for system alerts
ALERT_TELEGRAM_CHAT_ID=-1009876543210
```

### 4. Set Up Multiple Channels (Advanced)

To send different sources to different channels:

1. Modify the Telegram Dispatcher workflow
2. Add logic to route based on source:

```javascript
// In Format Message node
let chatId = process.env.TELEGRAM_DEFAULT_CHAT_ID;

// Route GitHub to different channel
if ($json.source === 'github') {
  chatId = '-1001111111111';
}

// Route Reddit to different channel
if ($json.source === 'reddit') {
  chatId = '-1002222222222';
}

return {
  ...message,
  chat_id: chatId
};
```

## GitHub Configuration

### 1. Generate Personal Access Token

1. Go to GitHub Settings ‚Üí Developer settings ‚Üí Personal access tokens
2. Click "Generate new token (classic)"
3. Select scopes:
   - `repo` (if monitoring private repos)
   - `public_repo` (if only public repos)
4. Copy the token (starts with `ghp_`)

### 2. Configure in .env

```bash
GITHUB_PERSONAL_ACCESS_TOKEN=ghp_your_token_here
GITHUB_WEBHOOK_SECRET=your_random_secret_here
```

### 3. Set Up Webhook

#### For Local Development (using ngrok):

1. Install ngrok: `npm install -g ngrok`
2. Start tunnel:
   ```bash
   ngrok http 5678
   ```
3. Copy the HTTPS URL (e.g., `https://abc123.ngrok.io`)

#### Configure Repository Webhook:

1. Go to your GitHub repository
2. Settings ‚Üí Webhooks ‚Üí Add webhook
3. Enter Payload URL:
   ```
   https://your-domain.com/webhook/github-webhook
   ```
   Or for ngrok:
   ```
   https://abc123.ngrok.io/webhook/github-webhook
   ```
4. Content type: `application/json`
5. Secret: Use value from `GITHUB_WEBHOOK_SECRET` in .env
6. Select events:
   - ‚úì Pushes
   - ‚úì Issues
   - ‚úì Pull requests
   - ‚úì Releases
7. Click "Add webhook"

### 4. Test Webhook

Make a test push to your repository and check:

1. GitHub webhook delivery (Settings ‚Üí Webhooks ‚Üí Recent Deliveries)
2. n8n execution log (Executions tab)
3. Telegram notification

### 5. Add to Database

```sql
INSERT INTO feed_sources (source_type, source_identifier, config, enabled)
VALUES (
  'github',
  'owner/repository',
  '{"events": ["push", "issues", "pull_request", "release"]}',
  true
);
```

### 6. GitHub API Monitoring (Alternative to Webhooks)

**Use this method when you want to monitor public repositories you don't own.**

#### Differences: Webhook vs API Polling

| Aspect | Webhook Monitor | API Polling Monitor |
|--------|----------------|---------------------|
| Use case | Your repositories | Any public repository |
| Latency | Real-time (<1s) | Up to 5 minutes |
| Setup | Webhook per repo | Database entry only |
| Requirements | Repo admin access | GitHub token only |
| Events | Push, PR, Issues, Releases | Commits, Issues |

#### Step 1: Generate Fine-grained Personal Access Token

1. Go to GitHub ‚Üí **Settings** ‚Üí **Developer settings** ‚Üí **Personal access tokens** ‚Üí **Fine-grained tokens**
2. Click **"Generate new token"**
3. Configure token:
   - **Token name**: `FeedOps API Monitor`
   - **Expiration**: 90 days (recommended)
   - **Repository access**: **Public Repositories (read-only)**
   - **Permissions**:
     - **Contents**: Read-only (for commits)
     - **Issues**: Read-only (for issues)
     - **Pull requests**: Read-only (optional)
4. Click **"Generate token"**
5. **Copy the token** (starts with `github_pat_`)

**Security Note**:
- Never commit tokens to git
- Set calendar reminder before expiration
- Regenerate token every 90 days

#### Step 2: Add Token to Environment

Edit `.env` file:
```bash
GITHUB_PERSONAL_ACCESS_TOKEN=github_pat_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

Restart n8n to load new environment variable:
```bash
docker-compose restart n8n
```

Verify token is loaded (optional):
```bash
docker exec feedops-n8n printenv | grep GITHUB_PERSONAL_ACCESS_TOKEN
```

#### Step 3: Configure HTTP Header Auth in n8n

1. Open n8n UI: `http://localhost:5678`
2. Go to **Credentials** (left sidebar)
3. Click **"+ Add Credential"**
4. Search for **"HTTP Header Auth"**
5. Configure:
   - **Name**: `GitHub API Token`
   - **Name** (header name): `Authorization`
   - **Value**: `Bearer {{$env.GITHUB_PERSONAL_ACCESS_TOKEN}}`
6. Click **"Save"**

#### Step 4: Import GitHub API Monitor Workflow

1. In n8n, go to **Workflows**
2. Click **"‚ãÆ"** menu ‚Üí **"Import from File"**
3. Select `workflows/05-github-api-monitor.json`
4. Click **"Save"**

**Important**: After importing, manually configure PostgreSQL query parameters (they don't import from JSON):

1. **Check Duplicate** node: Add parameter `1` = `={{$json.item_id}}`

2. **Log Notification** node: Add 6 parameters for the INSERT query:
   - Open the **"Log Notification"** node
   - Verify the query is:
     ```sql
     INSERT INTO notifications_history (source_id, item_id, item_hash, title, url, metadata)
     VALUES ($1, $2, $3, $4, $5, $6)
     ```
   - Scroll down and click **"Add Option"** ‚Üí **"Query Parameters"**
   - Click **"Add Parameter"** six times and configure each:
     - **Parameter 1**: `1` ‚Üí Value: `={{$json.source_id}}`
     - **Parameter 2**: `2` ‚Üí Value: `={{$json.item_id}}`
     - **Parameter 3**: `3` ‚Üí Value: `={{$json.content_hash}}`
     - **Parameter 4**: `4` ‚Üí Value: `={{$json.title}}`
     - **Parameter 5**: `5` ‚Üí Value: `={{$json.url}}`
     - **Parameter 6**: `6` ‚Üí Value: `={{JSON.stringify($json.metadata)}}`
   - Click **"Save"**

3. **Update Source Status** node: Add parameter `1` = `={{$json.source_id}}`

4. **Update Error Count** node: Add parameter `1` = `={{$json.source_id}}`

#### Step 5: Add Repositories to Monitor

**Via PostgreSQL**:

```bash
# Access PostgreSQL
docker exec -it feedops-postgres psql -U n8n -d n8n
```

**Basic monitoring** (commits + issues):
```sql
INSERT INTO feed_sources (source_type, source_identifier, config, enabled)
VALUES (
  'github_api',
  'kubernetes/kubernetes',
  '{"event_types": ["push", "issues"]}',
  true
);
```

**With keyword filtering**:
```sql
INSERT INTO feed_sources (source_type, source_identifier, config, enabled)
VALUES (
  'github_api',
  'docker/docker',
  '{"event_types": ["push"], "keywords": "security,vulnerability,cve"}',
  true
);
```

**Issues with required labels**:
```sql
INSERT INTO feed_sources (source_type, source_identifier, config, enabled)
VALUES (
  'github_api',
  'vercel/next.js',
  '{"event_types": ["issues"], "required_labels": "bug,confirmed"}',
  true
);
```

**Exclude pull requests**:
```sql
INSERT INTO feed_sources (source_type, source_identifier, config, enabled)
VALUES (
  'github_api',
  'facebook/react',
  '{"event_types": ["issues"], "include_pull_requests": false}',
  true
);
```

#### Step 6: Configuration Options

**Config JSON Structure**:
```json
{
  "event_types": ["push", "issues"],
  "keywords": "security,bug,feature",
  "required_labels": "priority-high,critical",
  "include_pull_requests": false
}
```

**Available Options**:

| Option | Type | Description | Example |
|--------|------|-------------|---------|
| `event_types` | Array | Events to monitor | `["push", "issues"]` |
| `keywords` | String | Filter by keywords (comma-separated) | `"security,bug"` |
| `required_labels` | String | Filter issues by labels (comma-separated) | `"bug,confirmed"` |
| `include_pull_requests` | Boolean | Include PRs in issue monitoring | `false` (default) |

#### Step 7: Activate Workflow

1. Open **GitHub API Monitor** workflow in n8n
2. Click **"Execute Workflow"** to test manually
3. Verify execution completes successfully
4. Toggle **"Active"** switch in top-right
5. Workflow now runs every 5 minutes

#### Step 8: Manage Repositories

**View all monitored repositories**:
```sql
SELECT
  id,
  source_identifier AS repository,
  config->'event_types' AS monitoring,
  enabled,
  last_check,
  error_count,
  created_at
FROM feed_sources
WHERE source_type = 'github_api'
ORDER BY created_at DESC;
```

**Enable/disable repository**:
```sql
-- Disable monitoring
UPDATE feed_sources
SET enabled = false
WHERE source_identifier = 'owner/repo' AND source_type = 'github_api';

-- Re-enable monitoring
UPDATE feed_sources
SET enabled = true
WHERE source_identifier = 'owner/repo' AND source_type = 'github_api';
```

**Update configuration**:
```sql
UPDATE feed_sources
SET config = '{"event_types": ["issues"], "required_labels": "security"}'
WHERE source_identifier = 'owner/repo' AND source_type = 'github_api';
```

**Delete repository**:
```sql
DELETE FROM feed_sources
WHERE source_identifier = 'owner/repo' AND source_type = 'github_api';
```

#### Rate Limits

**GitHub API Limits**:
- **Authenticated**: 5,000 requests/hour
- **Per endpoint**: No specific limit

**Calculate usage**:
- 10 repositories √ó 2 events √ó 12 polls/hour = **240 requests/hour**
- Leaves **4,760 requests** for other uses (95% available)

**Check current rate limit**:
```bash
curl -H "Authorization: Bearer YOUR_TOKEN" \
     https://api.github.com/rate_limit
```

**Response**:
```json
{
  "resources": {
    "core": {
      "limit": 5000,
      "remaining": 4760,
      "reset": 1704726000
    }
  }
}
```

#### Troubleshooting

**401 Unauthorized**:
```
Error: Request failed with status code 401
```
- **Cause**: Token invalid or expired
- **Solution**:
  1. Regenerate token in GitHub
  2. Update `.env` with new token
  3. Restart n8n: `docker-compose restart n8n`

**403 Forbidden (Rate Limit)**:
```
Error: API rate limit exceeded
```
- **Cause**: Too many requests
- **Solution**:
  1. Check rate limit: `curl ... /rate_limit`
  2. Reduce polling frequency (change to */15 or */30)
  3. Remove unused repositories

**404 Not Found**:
```
Error: Not Found
```
- **Cause**: Repository doesn't exist or is private
- **Solution**:
  1. Verify repository exists and is public
  2. Check `source_identifier` format: `owner/repo` (not full URL)

**No notifications received**:
- **Check filters**: Keywords or labels may be too restrictive
- **Check last_check**: May be too recent, no new activity
- **Check enabled**: Verify `enabled = true` in database
- **Check workflow**: Ensure workflow is active in n8n

**Duplicate notifications**:
- **Check deduplication**: Verify `item_id` generation is consistent
- **Check database**: Query `notifications_history` for duplicates

**High error_count**:
```sql
-- Find sources with errors
SELECT source_identifier, error_count, last_check
FROM feed_sources
WHERE source_type = 'github_api' AND error_count > 0;
```
- **Auto-disable after 5 errors**: Consider adding automated cleanup
- **Reset error count**: `UPDATE feed_sources SET error_count = 0 WHERE id = X;`

## Reddit Configuration

### 1. Create Reddit App

1. Go to https://www.reddit.com/prefs/apps
2. Click "Create App" or "Create Another App"
3. Fill in details:
   - **Name**: FeedOps
   - **Type**: script
   - **Description**: Feed monitoring bot
   - **Redirect URI**: `http://localhost:8080` (not used but required)
4. Click "Create app"
5. Copy:
   - **Client ID**: String under "personal use script"
   - **Client Secret**: Secret value

### 2. Configure in .env

```bash
REDDIT_CLIENT_ID=your_client_id_here
REDDIT_CLIENT_SECRET=your_secret_here
REDDIT_USERNAME=your_reddit_username
REDDIT_PASSWORD=your_reddit_password
REDDIT_USER_AGENT=FeedOps/1.0
```

### 3. Configure OAuth2 in n8n

1. Go to n8n ‚Üí Credentials
2. Find "Reddit OAuth2" credential
3. Verify settings match .env
4. Click "Connect my account" and authorize

### 4. Add Subreddit to Monitor

```sql
INSERT INTO feed_sources (source_type, source_identifier, config, enabled)
VALUES (
  'reddit',
  'r/programming',
  '{
    "min_score": 100,
    "keywords": "golang,rust,docker",
    "flair": "Tutorial"
  }',
  true
);
```

#### Config Options:

- **min_score**: Minimum upvotes required (integer)
- **keywords**: Comma-separated keywords to filter (case-insensitive)
- **flair**: Required post flair (exact match)

### 5. Adjust Polling Frequency

Edit `02-reddit-monitor.json`:

```json
{
  "parameters": {
    "rule": {
      "interval": [{
        "field": "cronExpression",
        "expression": "*/15 * * * *"  // Every 15 minutes
      }]
    }
  }
}
```

Common intervals:
- Every 5 minutes: `*/5 * * * *`
- Every 30 minutes: `*/30 * * * *`
- Every hour: `0 * * * *`
- Every 6 hours: `0 */6 * * *`

## RSS Configuration

### 1. Find RSS Feed URL

Most sites provide RSS feeds. Look for:
- RSS icon in browser/site
- `/feed`, `/rss`, or `/atom` URL paths
- `<link rel="alternate" type="application/rss+xml">` in HTML

Examples:
- **Hacker News**: `https://hnrss.org/newest`
- **Reddit**: `https://www.reddit.com/r/subreddit/.rss`
- **WordPress**: `https://example.com/feed`
- **Medium**: `https://medium.com/feed/@username`

### 2. Add RSS Feed

```sql
INSERT INTO feed_sources (source_type, source_identifier, config, enabled)
VALUES (
  'rss',
  'https://hnrss.org/newest',
  '{
    "keywords": "docker,kubernetes",
    "feed_name": "Hacker News"
  }',
  true
);
```

#### Config Options:

- **keywords**: Comma-separated keywords (searches title and content)
- **feed_name**: Friendly name for the feed (used in notifications)

### 3. Adjust Polling Frequency

Edit `03-rss-monitor.json`:

```json
{
  "parameters": {
    "rule": {
      "interval": [{
        "field": "cronExpression",
        "expression": "*/30 * * * *"  // Every 30 minutes
      }]
    }
  }
}
```

### 4. Test RSS Feed

Manually trigger the workflow:

1. Open "RSS Monitor" workflow in n8n
2. Click "Execute Workflow"
3. Check execution log
4. Verify items are fetched and filtered correctly

## Advanced Settings

### Custom Notification Templates

Edit the "Format Message" function in Telegram Dispatcher:

```javascript
// Add custom emoji per source
const customEmojis = {
  'github': {
    'push': 'üöÄ',
    'release': 'üéâ',
    'issues': 'üêõ',
    'pull_request': 'üîÄ'
  },
  'reddit': 'üî•',
  'rss': 'üì∞'
};

// Custom message format
let message = `${emoji} **${data.title}**\n\n`;

// Add custom fields
if (data.source === 'github') {
  message += `Repository: \`${data.repository}\`\n`;
  message += `Author: @${data.author}\n`;
}

// Add tags for filtering
if (data.metadata?.tags) {
  message += `Tags: ${data.metadata.tags.join(', ')}\n`;
}
```

### Rate Limiting

To avoid hitting API limits, configure delays:

#### Reddit:

```javascript
// Add delay between requests in Reddit Monitor
const delay = ms => new Promise(resolve => setTimeout(resolve, ms));

// After each request
await delay(1000); // 1 second delay
```

#### RSS:

```javascript
// Increase polling interval
"expression": "0 */2 * * *"  // Every 2 hours
```

### Deduplication Window

Adjust how long to keep notification history:

```sql
-- In PostgreSQL
UPDATE feedops_config
SET value = '60'
WHERE key = 'notification_retention_days';
```

Or modify cleanup script:
```bash
# In scripts/cleanup.sh
RETENTION_DAYS=60
```

### Error Handling

Customize retry behavior in Telegram Dispatcher:

```javascript
// Modify error handler
const maxRetries = 5;  // Instead of 3
const backoffMultiplier = 3;  // Instead of 2

// Delays: 3s, 9s, 27s, 81s, 243s
```

### Logging

Increase log verbosity for debugging:

```bash
# In .env
LOG_LEVEL=debug
```

View logs:
```bash
docker-compose logs -f n8n
```

### Production Settings

For production deployment:

```bash
# .env changes for production
N8N_PROTOCOL=https
WEBHOOK_URL=https://your-domain.com
SSL_ENABLED=true
DOMAIN=feedops.example.com
ACME_EMAIL=admin@example.com

# Start with Traefik profile
docker-compose --profile production up -d
```

## Manual Workflow Configuration

After importing workflows into n8n, some PostgreSQL nodes require manual configuration because query parameters don't import correctly from JSON files.

### GitHub Monitor Workflow

#### Check Duplicate Node

The "Check Duplicate" node in the GitHub Monitor workflow requires manual parameter configuration:

1. Open the **GitHub Monitor** workflow in n8n
2. Click on the **"Check Duplicate"** node
3. Verify the query is:
   ```sql
   SELECT item_hash FROM notifications_history WHERE item_hash = $1 LIMIT 1
   ```
4. Scroll down and click **"Add Option"**
5. Select **"Query Parameters"** from the dropdown
6. Click **"Add Parameter"**
7. Configure the parameter:
   - **Parameter**: `1` (just the number, not $1)
   - **Value**: `={{$json.content_hash}}`
8. Click **"Save"**

**Why this is needed:** The PostgreSQL node's query parameters don't import from JSON files. The `$1` placeholder in the query needs to be manually bound to the `content_hash` value from the previous node's output.

### Telegram Dispatcher Workflow

#### Update Notification Node

The "Update Notification" node in the Telegram Dispatcher workflow requires two parameters:

1. Open the **Telegram Dispatcher** workflow in n8n
2. Click on the **"Update Notification"** node
3. Verify the query is:
   ```sql
   UPDATE notifications_history SET telegram_message_id = $1 WHERE item_id = $2
   ```
4. Scroll down and click **"Add Option"**
5. Select **"Query Parameters"**
6. Click **"Add Parameter"** and configure **Parameter 1**:
   - **Parameter**: `1`
   - **Value**: `={{$json.message.message_id}}`
7. Click **"Add Parameter"** again and configure **Parameter 2**:
   - **Parameter**: `2`
   - **Value**: `={{$json.source_data.item_id}}`
8. Click **"Save"**

**Why this is needed:** This node updates the database with the Telegram message ID after successfully sending a notification, allowing tracking of which notifications were sent.

### Reddit Monitor Workflow

The Reddit Monitor workflow also has PostgreSQL nodes that may require manual parameter configuration:

- **Check Duplicate**: Parameter `1` = `={{$json.item_id}}`
- **Log Notification**: Uses INSERT with column mapping (should import correctly)
- **Update Source Status**: Parameter `1` = `={{$json.source_id}}`
- **Update Error Count**: Parameter `1` = `={{$json.source_id}}`

### RSS Monitor Workflow

Similar to Reddit Monitor:

- **Check Duplicate**: Parameter `1` = `={{$json.item_id}}`
- **Log Notification**: Uses INSERT with column mapping (should import correctly)
- **Update Source Status**: Parameter `1` = `={{$json.source_id}}`
- **Update Error Count**: Parameter `1` = `={{$json.source_id}}`

### General PostgreSQL Parameter Configuration

For any PostgreSQL node with parameterized queries:

1. Look for `$1`, `$2`, etc. in the SQL query
2. Add Query Parameters option
3. Match each `$N` with the corresponding parameter number
4. Use n8n expressions (`={{...}}`) to bind values from previous nodes

**Common errors if not configured:**
- `"there is no parameter $1"` - Query parameters not configured
- `"Node does not have any credentials set"` - PostgreSQL credentials not selected

### Verifying Configuration

After manual configuration, test each workflow:

1. Click **"Execute Workflow"** button
2. Check for errors in the execution log
3. Verify data flows correctly through all nodes
4. Confirm database queries execute successfully

If you see parameter errors, double-check that:
- Parameter numbers match (`1` for `$1`, `2` for `$2`, etc.)
- Values use correct n8n expressions
- Previous nodes output the expected data structure

## Workflow Customization

### Adding New Event Types

To add support for new GitHub events:

1. Configure webhook to send new events
2. Add handling in "Normalize Event" function:

```javascript
case 'star':
  normalized.title = `‚≠ê New star from ${body.sender.login}`;
  normalized.url = body.repository.html_url;
  break;
```

### Adding New Sources

To add a completely new source (e.g., Twitter):

1. Create new workflow file `workflows/05-twitter-monitor.json`
2. Add polling or webhook trigger
3. Implement normalization to standard format
4. Add deduplication check
5. Call Telegram Dispatcher
6. Import into n8n

Standard format:
```javascript
{
  source: 'twitter',
  source_id: '<uuid>',
  event_type: 'new_tweet',
  timestamp: '<ISO 8601>',
  item_id: '<unique_id>',
  content_hash: '<sha256>',
  title: '<tweet_text>',
  description: '',
  url: '<tweet_url>',
  author: '<username>',
  metadata: { /* source-specific data */ }
}
```

### Multiple Telegram Bots

To use different bots for different sources:

1. Create multiple Telegram credentials in n8n
2. Modify Telegram Dispatcher to select bot based on source:

```javascript
let credentialName = 'Telegram Bot';

if ($json.source === 'github') {
  credentialName = 'Telegram Bot GitHub';
} else if ($json.source === 'reddit') {
  credentialName = 'Telegram Bot Reddit';
}

// Use in Send Telegram node configuration
```

## Next Steps

- Review [N8N_WORKFLOWS.md](N8N_WORKFLOWS.md) for workflow details
- See [SCALABILITY.md](SCALABILITY.md) for scaling strategies
- Check [TROUBLESHOOTING.md](TROUBLESHOOTING.md) for common issues
